{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten\n",
    "from keras.optimizers import SGD, adam "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, 3, activation ='relu', input_shape = (150, 150, 3)))\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, 3, activation ='relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "model.add(Conv2D(128, 3, activation ='relu', input_shape = (150, 150, 3)))\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation = 'relu'))\n",
    "\n",
    "model.add(Dense(2, activation = 'softmax'))\n",
    "model.compile(SGD(lr = 0.001), loss = 'categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 23000 images belonging to 2 classes.\n",
      "Found 2000 images belonging to 2 classes.\n",
      "Epoch 1/1\n",
      "360/360 [==============================] - 643s 2s/step - loss: 0.6896 - acc: 0.5392 - val_loss: 0.6876 - val_acc: 0.5655\n"
     ]
    }
   ],
   "source": [
    "#keras image generator\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_dir='train/'\n",
    "valid_dir='validation/'\n",
    "test_dir='test/'\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale = (1./255), horizontal_flip = True)\n",
    "valid_datagen = ImageDataGenerator(rescale = (1./255))\n",
    "\n",
    "train_images = train_datagen.flow_from_directory(train_dir, target_size = (150,150), batch_size = 64)\n",
    "valid_images = valid_datagen.flow_from_directory(valid_dir, target_size = (150,150), batch_size = 64)\n",
    "\n",
    "model.fit_generator(train_images, steps_per_epoch = len(train_images), epochs = 3, validation_data = valid_images, validation_steps = len(valid_images), verbose = 1)\n",
    "\n",
    "model.save('cvd.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__iter__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__next__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_flow_index',\n",
       " '_get_batches_of_transformed_samples',\n",
       " '_set_index_array',\n",
       " '_tf_api_names',\n",
       " '_tf_api_names_v1',\n",
       " 'allowed_class_modes',\n",
       " 'batch_index',\n",
       " 'batch_size',\n",
       " 'class_indices',\n",
       " 'class_mode',\n",
       " 'classes',\n",
       " 'color_mode',\n",
       " 'data',\n",
       " 'data_format',\n",
       " 'directory',\n",
       " 'dtype',\n",
       " 'filenames',\n",
       " 'filepaths',\n",
       " 'image_data_generator',\n",
       " 'image_shape',\n",
       " 'index_array',\n",
       " 'index_generator',\n",
       " 'interpolation',\n",
       " 'labels',\n",
       " 'lock',\n",
       " 'n',\n",
       " 'next',\n",
       " 'num_classes',\n",
       " 'on_epoch_end',\n",
       " 'reset',\n",
       " 'samples',\n",
       " 'save_format',\n",
       " 'save_prefix',\n",
       " 'save_to_dir',\n",
       " 'seed',\n",
       " 'set_processing_attrs',\n",
       " 'shuffle',\n",
       " 'split',\n",
       " 'subset',\n",
       " 'target_size',\n",
       " 'total_batches_seen',\n",
       " 'white_list_formats']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(valid_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dog\\\\dog.999.jpg'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_images.filenames[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
